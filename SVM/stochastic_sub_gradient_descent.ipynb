{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "#upload dataset\n",
    "train_data = pd.read_csv(\"D:/EIC-Code/00-Python/Machine-Learning-HW/SVM/bank-note/train.csv\", header = None, names = ['variance','skewness','curtosis','entropy','y'])\n",
    "test_data = pd.read_csv(\"D:/EIC-Code/00-Python/Machine-Learning-HW/SVM/bank-note/test.csv\", names = ['variance','skewness','curtosis','entropy','y'])\n",
    "\n",
    "features = ['variance','skewness','curtosis','entropy']\n",
    "outcome = 'y'\n",
    "\n",
    "X_train = train_data[features].values #change to matrix multiple\n",
    "y_train = train_data[outcome].values\n",
    "X_test = test_data[features].values\n",
    "y_test = test_data[outcome].values\n",
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimalSVM:\n",
    "    def __init__(self, gamma, a, C, N):\n",
    "        \"\"\"\n",
    "        Initialize the SVM model with hyperparameters.\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.a = a\n",
    "        self.C = C\n",
    "        self.N = N\n",
    "        self.w = None  # Weight vector will be initialized during training\n",
    "\n",
    "    def fit(self, X, y, epochs, schedule):\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)  # Initialize weights to zeros\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            data = np.column_stack((X, y))\n",
    "            np.random.shuffle(data)  # Shuffle training data\n",
    "            X_shuffled = data[:, :-1]\n",
    "            y_shuffled = data[:, -1]\n",
    "\n",
    "            for i, (xi, yi) in enumerate(zip(X_shuffled, y_shuffled)):\n",
    "                t = epoch * len(y_shuffled) + i + 1  # Global step count\n",
    "                \n",
    "                # Learning rate schedules\n",
    "                if schedule == \"schedule1\":\n",
    "                    gamma_t = self.gamma / (1 + (self.gamma / self.a) * t)\n",
    "                elif schedule == \"schedule2\":\n",
    "                    gamma_t = self.gamma / (1 + t)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid schedule. Choose 'schedule1' or 'schedule2'.\")\n",
    "\n",
    "\n",
    "                if yi * np.dot(self.w, xi) <= 1:\n",
    "                    self.w = self.w - gamma_t * self.w + gamma_t * self.C * self.N * yi * xi\n",
    "                else:\n",
    "                    self.w = (1 - gamma_t) * self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(X.dot(self.w))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        errors = np.mean(predictions != y)\n",
    "        return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: C=0.1145475372279496, gamma=0.1, a=1, train_error: 0.19839449541284404, test_error:0.196\n",
      "Testing: C=0.1145475372279496, gamma=0.1, a=10, train_error: 0.2018348623853211, test_error:0.196\n",
      "Testing: C=0.1145475372279496, gamma=0.1, a=100, train_error: 0.1823394495412844, test_error:0.176\n",
      "Testing: C=0.1145475372279496, gamma=0.01, a=1, train_error: 0.25688073394495414, test_error:0.252\n",
      "Testing: C=0.1145475372279496, gamma=0.01, a=10, train_error: 0.30504587155963303, test_error:0.308\n",
      "Testing: C=0.1145475372279496, gamma=0.01, a=100, train_error: 0.25688073394495414, test_error:0.264\n",
      "Testing: C=0.1145475372279496, gamma=0.001, a=1, train_error: 0.31880733944954126, test_error:0.326\n",
      "Testing: C=0.1145475372279496, gamma=0.001, a=10, train_error: 0.31995412844036697, test_error:0.328\n",
      "Testing: C=0.1145475372279496, gamma=0.001, a=100, train_error: 0.33142201834862384, test_error:0.334\n",
      "Testing: C=0.572737686139748, gamma=0.1, a=1, train_error: 0.06077981651376147, test_error:0.076\n",
      "Testing: C=0.572737686139748, gamma=0.1, a=10, train_error: 0.06077981651376147, test_error:0.084\n",
      "Testing: C=0.572737686139748, gamma=0.1, a=100, train_error: 0.06077981651376147, test_error:0.074\n",
      "Testing: C=0.572737686139748, gamma=0.01, a=1, train_error: 0.22591743119266056, test_error:0.22\n",
      "Testing: C=0.572737686139748, gamma=0.01, a=10, train_error: 0.24885321100917432, test_error:0.246\n",
      "Testing: C=0.572737686139748, gamma=0.01, a=100, train_error: 0.22591743119266056, test_error:0.224\n",
      "Testing: C=0.572737686139748, gamma=0.001, a=1, train_error: 0.3211009174311927, test_error:0.326\n",
      "Testing: C=0.572737686139748, gamma=0.001, a=10, train_error: 0.28784403669724773, test_error:0.29\n",
      "Testing: C=0.572737686139748, gamma=0.001, a=100, train_error: 0.30619266055045874, test_error:0.306\n",
      "Testing: C=0.8018327605956472, gamma=0.1, a=1, train_error: 0.05504587155963303, test_error:0.074\n",
      "Testing: C=0.8018327605956472, gamma=0.1, a=10, train_error: 0.05389908256880734, test_error:0.072\n",
      "Testing: C=0.8018327605956472, gamma=0.1, a=100, train_error: 0.05389908256880734, test_error:0.072\n",
      "Testing: C=0.8018327605956472, gamma=0.01, a=1, train_error: 0.19495412844036697, test_error:0.184\n",
      "Testing: C=0.8018327605956472, gamma=0.01, a=10, train_error: 0.24541284403669725, test_error:0.244\n",
      "Testing: C=0.8018327605956472, gamma=0.01, a=100, train_error: 0.21559633027522937, test_error:0.212\n",
      "Testing: C=0.8018327605956472, gamma=0.001, a=1, train_error: 0.2809633027522936, test_error:0.286\n",
      "Testing: C=0.8018327605956472, gamma=0.001, a=10, train_error: 0.22821100917431192, test_error:0.226\n",
      "Testing: C=0.8018327605956472, gamma=0.001, a=100, train_error: 0.3268348623853211, test_error:0.318\n",
      "Testing: C=873, gamma=0.1, a=1, train_error: 0.04357798165137615, test_error:0.066\n",
      "Testing: C=873, gamma=0.1, a=10, train_error: 0.04472477064220184, test_error:0.058\n",
      "Testing: C=873, gamma=0.1, a=100, train_error: 0.045871559633027525, test_error:0.048\n",
      "Testing: C=873, gamma=0.01, a=1, train_error: 0.04243119266055046, test_error:0.058\n",
      "Testing: C=873, gamma=0.01, a=10, train_error: 0.04243119266055046, test_error:0.05\n",
      "Testing: C=873, gamma=0.01, a=100, train_error: 0.04357798165137615, test_error:0.052\n",
      "Testing: C=873, gamma=0.001, a=1, train_error: 0.04128440366972477, test_error:0.044\n",
      "Testing: C=873, gamma=0.001, a=10, train_error: 0.04357798165137615, test_error:0.054\n",
      "Testing: C=873, gamma=0.001, a=100, train_error: 0.04243119266055046, test_error:0.06\n",
      "Best parameters: C=873, gamma=0.001, a=1\n",
      "Best accuracy: 0.044\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search space\n",
    "Cs = [100 / 873, 500 / 873, 700 / 873, 873]\n",
    "gamma_values = [0.1, 0.01, 0.001]\n",
    "a_values = [1, 10, 100]\n",
    "N = 1\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "lowest_error = 10000\n",
    "best_params = None\n",
    "\n",
    "for C in Cs:\n",
    "    for gamma in gamma_values:\n",
    "        for a in a_values:\n",
    "            svm = PrimalSVM(gamma=gamma, a=a, C=C, N=N)\n",
    "            \n",
    "            svm.fit(X_train, y_train, epochs=epochs, schedule=\"schedule2\")\n",
    "            train_errors = svm.score(X_train, y_train)\n",
    "            test_errors = svm.score(X_test, y_test)\n",
    "            print(f\"Testing: C={C}, gamma={gamma}, a={a}, train_error: {train_errors}, test_error:{test_errors}\")\n",
    "\n",
    "            if test_errors < lowest_error:\n",
    "                lowest_error = test_errors\n",
    "                best_params = (C, gamma, a)\n",
    "\n",
    "print(f\"Best parameters: C={best_params[0]}, gamma={best_params[1]}, a={best_params[2]}\")\n",
    "print(f\"Best accuracy: {lowest_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DuallSVM:\n",
    "    def __init__(self, gamma, a, C, N):\n",
    "        \"\"\"\n",
    "        Initialize the SVM model with hyperparameters.\n",
    "        \"\"\"\n",
    "        self.gamma = gamma\n",
    "        self.a = a\n",
    "        self.C = C\n",
    "        self.N = N\n",
    "        self.w = None  # Weight vector will be initialized during training\n",
    "\n",
    "    def fit(self, X, y, epochs, schedule):\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)  # Initialize weights to zeros\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            data = np.column_stack((X, y))\n",
    "            np.random.shuffle(data)  # Shuffle training data\n",
    "            X_shuffled = data[:, :-1]\n",
    "            y_shuffled = data[:, -1]\n",
    "\n",
    "            for i, (xi, yi) in enumerate(zip(X_shuffled, y_shuffled)):\n",
    "                t = epoch * len(y_shuffled) + i + 1  # Global step count\n",
    "                \n",
    "                # Learning rate schedules\n",
    "                if schedule == \"schedule1\":\n",
    "                    gamma_t = self.gamma / (1 + (self.gamma / self.a) * t)\n",
    "                elif schedule == \"schedule2\":\n",
    "                    gamma_t = self.gamma / (1 + t)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid schedule. Choose 'schedule1' or 'schedule2'.\")\n",
    "\n",
    "\n",
    "                if yi * np.dot(self.w, xi) <= 1:\n",
    "                    self.w = self.w - gamma_t * self.w + gamma_t * self.C * self.N * yi * xi\n",
    "                else:\n",
    "                    self.w = (1 - gamma_t) * self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(X.dot(self.w))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        errors = np.mean(predictions != y)\n",
    "        return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gamma \u001b[38;5;129;01min\u001b[39;00m gamma_values:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m a_values:\n\u001b[1;32m---> 20\u001b[0m         svm \u001b[38;5;241m=\u001b[39m \u001b[43mprimal_SVM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m         accuracy \u001b[38;5;241m=\u001b[39m svm(X_test, y_test)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting: C=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, gamma=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgamma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, a=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Cross-validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'epochs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
