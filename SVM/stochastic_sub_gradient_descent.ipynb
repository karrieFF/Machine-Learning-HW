{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload dataset\n",
    "train_data = pd.read_csv(\"D:/EIC-Code/00-Python/Machine-Learning-HW/SVM/bank-note/train.csv\", header = None, names = ['variance','skewness','curtosis','entropy','y'])\n",
    "test_data = pd.read_csv(\"D:/EIC-Code/00-Python/Machine-Learning-HW/SVM/bank-note/test.csv\", names = ['variance','skewness','curtosis','entropy','y'])\n",
    "\n",
    "features = ['variance','skewness','curtosis','entropy']\n",
    "outcome = 'y'\n",
    "\n",
    "X_train = train_data[features].values #change to matrix multiple\n",
    "y_train = train_data[outcome].values\n",
    "X_test = test_data[features].values\n",
    "y_test = test_data[outcome].values\n",
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimalSVM:\n",
    "    def __init__(self, gamma, a, C, N):\n",
    "        self.gamma = gamma\n",
    "        self.a = a\n",
    "        self.C = C\n",
    "        self.N = N\n",
    "        self.w = None  # Weight vector will be initialized during training\n",
    "\n",
    "    def fit(self, X, y, epochs, schedule):\n",
    "        n_features = X.shape[1]\n",
    "        self.w = np.zeros(n_features)  # Initialize weights to zeros\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            data = np.column_stack((X, y))\n",
    "            np.random.shuffle(data)  # Shuffle training data\n",
    "            X_shuffled = data[:, :-1]\n",
    "            y_shuffled = data[:, -1]\n",
    "\n",
    "            for i, (xi, yi) in enumerate(zip(X_shuffled, y_shuffled)):\n",
    "                t = epoch * len(y_shuffled) + i + 1  # Global step count\n",
    "                \n",
    "                # Learning rate schedules\n",
    "                if schedule == \"schedule1\":\n",
    "                    gamma_t = self.gamma / (1 + (self.gamma / self.a) * t)\n",
    "                elif schedule == \"schedule2\":\n",
    "                    gamma_t = self.gamma / (1 + t)\n",
    "                else:\n",
    "                    raise ValueError(\"Invalid schedule. Choose 'schedule1' or 'schedule2'.\")\n",
    "\n",
    "                if yi * np.dot(self.w, xi) <= 1:\n",
    "                    self.w = self.w - gamma_t * self.w + gamma_t * self.C * self.N * yi * xi\n",
    "                else:\n",
    "                    self.w = (1 - gamma_t) * self.w\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(X.dot(self.w))\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        errors = np.mean(predictions != y)\n",
    "        return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: C=0.1145475372279496, gamma=0.1, a=1, train_error: 0.22477064220183487, test_error:0.218\n",
      "Testing: C=0.1145475372279496, gamma=0.1, a=10, train_error: 0.18807339449541285, test_error:0.172\n",
      "Testing: C=0.1145475372279496, gamma=0.1, a=100, train_error: 0.19724770642201836, test_error:0.19\n",
      "Testing: C=0.1145475372279496, gamma=0.01, a=1, train_error: 0.30275229357798167, test_error:0.304\n",
      "Testing: C=0.1145475372279496, gamma=0.01, a=10, train_error: 0.3256880733944954, test_error:0.33\n",
      "Testing: C=0.1145475372279496, gamma=0.01, a=100, train_error: 0.30275229357798167, test_error:0.306\n",
      "Testing: C=0.1145475372279496, gamma=0.001, a=1, train_error: 0.2798165137614679, test_error:0.286\n",
      "Testing: C=0.1145475372279496, gamma=0.001, a=10, train_error: 0.3302752293577982, test_error:0.334\n",
      "Testing: C=0.1145475372279496, gamma=0.001, a=100, train_error: 0.2511467889908257, test_error:0.252\n",
      "Testing: C=0.572737686139748, gamma=0.1, a=1, train_error: 0.06077981651376147, test_error:0.084\n",
      "Testing: C=0.572737686139748, gamma=0.1, a=10, train_error: 0.06077981651376147, test_error:0.076\n",
      "Testing: C=0.572737686139748, gamma=0.1, a=100, train_error: 0.06077981651376147, test_error:0.084\n",
      "Testing: C=0.572737686139748, gamma=0.01, a=1, train_error: 0.24426605504587157, test_error:0.232\n",
      "Testing: C=0.572737686139748, gamma=0.01, a=10, train_error: 0.23509174311926606, test_error:0.234\n",
      "Testing: C=0.572737686139748, gamma=0.01, a=100, train_error: 0.25688073394495414, test_error:0.248\n",
      "Testing: C=0.572737686139748, gamma=0.001, a=1, train_error: 0.30275229357798167, test_error:0.302\n",
      "Testing: C=0.572737686139748, gamma=0.001, a=10, train_error: 0.32454128440366975, test_error:0.326\n",
      "Testing: C=0.572737686139748, gamma=0.001, a=100, train_error: 0.2580275229357798, test_error:0.266\n",
      "Testing: C=0.8018327605956472, gamma=0.1, a=1, train_error: 0.05389908256880734, test_error:0.076\n",
      "Testing: C=0.8018327605956472, gamma=0.1, a=10, train_error: 0.05389908256880734, test_error:0.078\n",
      "Testing: C=0.8018327605956472, gamma=0.1, a=100, train_error: 0.05389908256880734, test_error:0.078\n",
      "Testing: C=0.8018327605956472, gamma=0.01, a=1, train_error: 0.2018348623853211, test_error:0.194\n",
      "Testing: C=0.8018327605956472, gamma=0.01, a=10, train_error: 0.20642201834862386, test_error:0.198\n",
      "Testing: C=0.8018327605956472, gamma=0.01, a=100, train_error: 0.15022935779816513, test_error:0.154\n",
      "Testing: C=0.8018327605956472, gamma=0.001, a=1, train_error: 0.27408256880733944, test_error:0.28\n",
      "Testing: C=0.8018327605956472, gamma=0.001, a=10, train_error: 0.33142201834862384, test_error:0.332\n",
      "Testing: C=0.8018327605956472, gamma=0.001, a=100, train_error: 0.34288990825688076, test_error:0.344\n",
      "Best parameters: C=0.572737686139748, gamma=0.1, a=10\n",
      "Lowest error: 0.076\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Define hyperparameter search space\n",
    "Cs = [100 / 873, 500 / 873, 700 / 873]\n",
    "gamma_values = [0.1, 0.01, 0.001]#\n",
    "a_values = [1, 10, 100]\n",
    "N = 1\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "lowest_error = 10000 #float(\"inf\")\n",
    "best_params = None\n",
    "\n",
    "for C in Cs:\n",
    "    for gamma in gamma_values:\n",
    "        for a in a_values:\n",
    "            svm = PrimalSVM(gamma=gamma, a=a, C=C, N=N)\n",
    "            \n",
    "            svm.fit(X_train, y_train, epochs=epochs, schedule=\"schedule2\")\n",
    "            train_errors = svm.score(X_train, y_train)\n",
    "            test_errors = svm.score(X_test, y_test)\n",
    "            print(f\"Testing: C={C}, gamma={gamma}, a={a}, train_error: {train_errors}, test_error:{test_errors}\")\n",
    "\n",
    "            if test_errors < lowest_error:\n",
    "                lowest_error = test_errors\n",
    "                best_params = (C, gamma, a)\n",
    "\n",
    "print(f\"Best parameters: C={best_params[0]}, gamma={best_params[1]}, a={best_params[2]}\")\n",
    "print(f\"Lowest error: {lowest_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class DualSVM:\n",
    "    def __init__(self, C):\n",
    "        self.C = C  # Regularization parameter\n",
    "        self.alpha = None  # Lagrange multipliers\n",
    "        self.w = None  # Weight vector\n",
    "        self.b = None  # Bias term\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # kernel matrix (linear kernel)\n",
    "        K = np.dot(X, X.T)\n",
    "\n",
    "        # define the dual objective function\n",
    "        def objective(alpha):\n",
    "            return -np.sum(alpha) + 0.5 * np.sum((alpha * y)[:, None] * (alpha * y) * K)\n",
    "\n",
    "        # Initial guess for alpha\n",
    "        alpha0 = np.zeros(n_samples)\n",
    "\n",
    "        # Bounds for alpha: 0 <= alpha <= C\n",
    "        bounds = [(0, C) for _ in range(n_samples)]\n",
    "\n",
    "        # Equality constraint: sum(alpha * y) = 0\n",
    "        constraints = {\n",
    "            'type': 'eq',\n",
    "            'fun': lambda alpha: np.dot(alpha, y),\n",
    "            'jac': lambda alpha: y\n",
    "}\n",
    "        # Solve the optimization problem\n",
    "        result = minimize(\n",
    "            objective,\n",
    "            alpha0,\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=constraints\n",
    "        )\n",
    "\n",
    "        # extract the optimal alpha\n",
    "        self.alpha = result.x #minimize the function to get alpha\n",
    "\n",
    "        # compute weight vector\n",
    "        self.w = np.sum((self.alpha * y)[:, None] * X, axis=0)\n",
    "\n",
    "        # compute bias term\n",
    "        support_vector_idx = np.where((self.alpha > 0) & (self.alpha < self.C))[0][0]\n",
    "        self.b = y[support_vector_idx] - np.dot(self.w, X[support_vector_idx])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.w) + self.b)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions != y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EID-Download\\02 Academic\\Python38\\lib\\site-packages\\scipy\\optimize\\_optimize.py:353: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1145475372279496, Train Accuracy=0.11, Test Accuracy=0.12\n",
      "Weights:, [-0.94292598 -0.65149184 -0.73372197 -0.04102195], Bias:, 4.14119177534919\n",
      "C=0.572737686139748, Train Accuracy=0.15, Test Accuracy=0.14\n",
      "Weights:, [-1.56393784 -1.01405165 -1.18065044 -0.15651687], Bias:, 7.590350666124916\n",
      "C=0.8018327605956472, Train Accuracy=0.40, Test Accuracy=0.43\n",
      "Weights:, [-2.04254833 -1.28068891 -1.51351532 -0.24905307], Bias:, 12.975949611428163\n",
      "Weights: [-2.04254833 -1.28068891 -1.51351532 -0.24905307]\n",
      "Bias: 12.975949611428163\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Define hyperparameter C\n",
    "Cs = [100 / 873, 500 / 873, 700 / 873] #, 873\n",
    "\n",
    "# Train and evaluate the model for different values of C\n",
    "for C in Cs:\n",
    "    svm = DualSVM(C)\n",
    "    svm.fit(X_train, y_train)\n",
    "    train_error = svm.score(X_train, y_train)\n",
    "    test_error = svm.score(X_test, y_test)\n",
    "    print(f\"C={C}, Train Accuracy={train_error:.2f}, Test Accuracy={test_error:.2f}\")\n",
    "    print(f\"Weights:, {svm.w}, Bias:, {svm.b}\")\n",
    "\n",
    "# Print the weights and bias for the best model\n",
    "print(\"Weights:\", svm.w)\n",
    "print(\"Bias:\", svm.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class GaussianSVM:\n",
    "    def __init__(self, C, gamma):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.alpha = None  # lagrange multipliers\n",
    "        self.b = None  # bias term\n",
    "        self.X_train = None  # training features\n",
    "        self.y_train = None  # training labels\n",
    "\n",
    "    def gaussian_kernel(self, x1, x2):\n",
    "        return np.exp(-np.linalg.norm(x1 - x2) ** 2 / self.gamma)\n",
    "\n",
    "    def kernel_matrix(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i, j] = self.gaussian_kernel(X[i], X[j])\n",
    "        return K\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Compute the kernel matrix\n",
    "        K = self.kernel_matrix(X)\n",
    "\n",
    "        # Define the dual objective function\n",
    "        def objective(alpha):\n",
    "            return -np.sum(alpha) + 0.5 * np.sum((alpha * y)[:, None] * (alpha * y) * K)\n",
    "\n",
    "        # Bounds for alpha: 0 <= alpha <= C\n",
    "        bounds = [(0, self.C) for _ in range(n_samples)]\n",
    "\n",
    "        # Equality constraint: sum(alpha * y) = 0\n",
    "        constraints = {\n",
    "            'type': 'eq',\n",
    "            'fun': lambda alpha: np.dot(alpha, y),\n",
    "            'jac': lambda alpha: y\n",
    "        }\n",
    "\n",
    "        # Initial guess for alpha\n",
    "        alpha0 = np.zeros(n_samples)\n",
    "\n",
    "        # Solve the optimization problem\n",
    "        result = minimize(\n",
    "            objective,\n",
    "            alpha0,\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=constraints,\n",
    "            options={'maxiter': 1000, 'disp': True}\n",
    "        )\n",
    "\n",
    "        # Extract the optimal alpha\n",
    "        self.alpha = result.x\n",
    "\n",
    "        # Compute bias term using support vectors\n",
    "        support_vector_idx = np.where((self.alpha > 1e-4) & (self.alpha < self.C))[0]\n",
    "        support_vector_idx = support_vector_idx[0]\n",
    "        self.b = y[support_vector_idx] - np.sum(self.alpha * y * K[support_vector_idx])\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            # Decision function\n",
    "            decision = np.sum(\n",
    "                self.alpha * self.y_train *\n",
    "                np.array([self.gaussian_kernel(x, x_train) for x_train in self.X_train])\n",
    "            ) + self.b\n",
    "            y_pred.append(np.sign(decision))\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions != y)  # Error rate\n",
    "\n",
    "    def get_support_vectors(self):\n",
    "        return np.where((self.alpha > 1e-4) & (self.alpha < self.C))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -82.72279493439663\n",
      "            Iterations: 15\n",
      "            Function evaluations: 13098\n",
      "            Gradient evaluations: 15\n",
      "C=0.1145, gamma=0.1, Train error=0.4461, Test error=0.4420\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -74.16551934430456\n",
      "            Iterations: 23\n",
      "            Function evaluations: 20084\n",
      "            Gradient evaluations: 23\n",
      "C=0.1145, gamma=0.5, Train error=0.4071, Test error=0.4260\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "Cs = [100 / 873, 500 / 873, 700 / 873] #, 873\n",
    "gammas = [0.1, 0.5, 1, 5, 100]\n",
    "\n",
    "lowest_error = float(\"inf\")\n",
    "best_params = None\n",
    "\n",
    "for C in Cs:\n",
    "    for gamma in gammas:\n",
    "        gsvm = GaussianSVM(C, gamma)\n",
    "        gsvm.fit(X_train, y_train)\n",
    "        train_error = gsvm.score(X_train, y_train)\n",
    "        test_error = gsvm.score(X_test, y_test)\n",
    "        print(f\"C={C:.4f}, gamma={gamma}, Train error={train_error:.4f}, Test error={test_error:.4f}\")\n",
    "\n",
    "        if test_error < lowest_error:\n",
    "            lowest_error = test_error\n",
    "            best_params = (C, gamma)\n",
    "\n",
    "print(f\"Best Parameters: C={best_params[0]:.4f}, gamma={best_params[1]}\")\n",
    "print(f\"Best Test Error: {lowest_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -40.666358159348846\n",
      "            Iterations: 7\n",
      "            Function evaluations: 707\n",
      "            Gradient evaluations: 7\n",
      "Gamma=0.01, Number of Support Vectors: 5\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -40.560207048926294\n",
      "            Iterations: 14\n",
      "            Function evaluations: 1415\n",
      "            Gradient evaluations: 14\n",
      "Gamma=0.1, Number of Support Vectors: 100\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -45.44525533458662\n",
      "            Iterations: 21\n",
      "            Function evaluations: 2121\n",
      "            Gradient evaluations: 21\n",
      "Gamma=0.5, Number of Support Vectors: 97\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -48.99569233826322\n",
      "            Iterations: 24\n",
      "            Function evaluations: 2424\n",
      "            Gradient evaluations: 24\n",
      "Gamma=1, Number of Support Vectors: 6\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -52.69957543413841\n",
      "            Iterations: 18\n",
      "            Function evaluations: 1818\n",
      "            Gradient evaluations: 18\n",
      "Gamma=5, Number of Support Vectors: 5\n",
      "Overlap between gamma=0.01 and gamma=0.1: 5\n",
      "Overlap between gamma=0.1 and gamma=0.5: 97\n",
      "Overlap between gamma=0.5 and gamma=1: 5\n",
      "Overlap between gamma=1 and gamma=5: 0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# Parameters\n",
    "C = 500 / 873 \n",
    "gammas = [0.01, 0.1, 0.5, 1, 5]\n",
    "\n",
    "# Track support vectors\n",
    "support_vectors = {}\n",
    "\n",
    "for gamma in gammas:\n",
    "    gsvm = GaussianSVM(C=C, gamma=gamma)\n",
    "    gsvm.fit(X_train, y_train)\n",
    "    sv_indices = gsvm.get_support_vectors()\n",
    "    support_vectors[gamma] = sv_indices\n",
    "    print(f\"Gamma={gamma}, Number of Support Vectors: {len(sv_indices)}\")\n",
    "\n",
    "# Calculate overlaps between consecutive gammas\n",
    "for i in range(len(gammas) - 1):\n",
    "    gamma1, gamma2 = gammas[i], gammas[i + 1]\n",
    "    overlap = len(np.intersect1d(support_vectors[gamma1], support_vectors[gamma2]))\n",
    "    print(f\"Overlap between gamma={gamma1} and gamma={gamma2}: {overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KernelPerceptron:\n",
    "    def __init__(self, gamma, max_epochs=10):\n",
    "        self.gamma = gamma\n",
    "        self.max_epochs = max_epochs\n",
    "        self.c = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def gaussian_kernel(self, x1, x2):\n",
    "        return np.exp(-np.linalg.norm(x1 - x2)**2 / self.gamma)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        N = X.shape[0]\n",
    "        self.c = np.zeros(N)  # Mistake counts\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "            for i in range(N):\n",
    "                # Compute decision function\n",
    "                decision = sum(self.c[j] * y[j] * self.gaussian_kernel(X[j], X[i]) for j in range(N))\n",
    "                if y[i] * decision <= 0:  # Misclassified\n",
    "                    self.c[i] += 1  # Update mistake count\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            # Compute decision function for new point\n",
    "            decision = sum(self.c[i] * self.y_train[i] * self.gaussian_kernel(self.X_train[i], x) for i in range(len(self.X_train)))\n",
    "            y_pred.append(np.sign(decision))\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions != y)  # Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "# Test different gamma values\n",
    "gammas = [0.1, 0.5, 1, 5, 100]\n",
    "for gamma in gammas:\n",
    "    kp = KernelPerceptron(gamma=gamma)\n",
    "    kp.fit(X_train, y_train)\n",
    "    train_error = kp.score(X_train, y_train)\n",
    "    test_error = kp.score(X_test, y_test)\n",
    "    print(f\"Gamma={gamma}, Train Accuracy={train_error:.4f}, Test Accuracy={test_error:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
