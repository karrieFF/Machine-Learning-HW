{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import SVMpkg\n",
    "# Seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload dataset\n",
    "train_data = pd.read_csv(\"D:/EIC-Code/00-Python/Machine-Learning-HW/SVM/bank-note/train.csv\", header = None, names = ['variance','skewness','curtosis','entropy','y'])\n",
    "test_data = pd.read_csv(\"D:/EIC-Code/00-Python/Machine-Learning-HW/SVM/bank-note/test.csv\", names = ['variance','skewness','curtosis','entropy','y'])\n",
    "\n",
    "features = ['variance','skewness','curtosis','entropy']\n",
    "outcome = 'y'\n",
    "\n",
    "X_train = train_data[features].values #change to matrix multiple\n",
    "y_train = train_data[outcome].values\n",
    "X_test = test_data[features].values\n",
    "y_test = test_data[outcome].values\n",
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters for schedule1:\n",
      "C=0.114548, Schedule: schedule1, gamma=0.5, a=100, train_error: 0.0608, test_error: 0.0840, weights: [-0.15217176 -0.11147137 -0.05579284 -0.01562807], bias: 0.14298246924389865\n",
      "C=0.572738, Schedule: schedule1, gamma=0.01, a=1, train_error: 0.0241, test_error: 0.0180, weights: [-0.32441602 -0.17212906 -0.18608215 -0.02517079], bias: 0.5004602638064877\n",
      "C=0.801833, Schedule: schedule1, gamma=0.001, a=100, train_error: 0.0183, test_error: 0.0160, weights: [-0.34762413 -0.18979735 -0.22631406 -0.00247417], bias: 0.6468729605176408\n",
      "\n",
      "Best Parameters for schedule2:\n",
      "C=0.114548, Schedule: schedule2, gamma=1, a=50, train_error: 0.0631, test_error: 0.0860, weights: [-0.15368874 -0.11439085 -0.05609331 -0.01529727], bias: 0.1352745796472408\n",
      "C=0.572738, Schedule: schedule2, gamma=1, a=10, train_error: 0.0218, test_error: 0.0160, weights: [-0.32397074 -0.17102877 -0.18428299 -0.02530887], bias: 0.4902974613772339\n",
      "C=0.801833, Schedule: schedule2, gamma=1, a=10, train_error: 0.0241, test_error: 0.0180, weights: [-0.3530895  -0.18560306 -0.21316165 -0.01371438], bias: 0.5985959503707144\n"
     ]
    }
   ],
   "source": [
    "# PrimalSVM\n",
    "Cs = [100 / 873, 500 / 873, 700 / 873]\n",
    "gamma_values = [1, 0.5, 0.1, 0.01, 0.001]\n",
    "a_values = [1, 10, 50, 100]\n",
    "N = 1\n",
    "epochs = 100\n",
    "\n",
    "# Initialize variables to track the best parameters and lowest error for each schedule and C\n",
    "best_params_per_schedule = {\"schedule1\": {}, \"schedule2\": {}}\n",
    "\n",
    "# Perform grid search\n",
    "for schedule in [\"schedule1\", \"schedule2\"]:\n",
    "    for C in Cs:\n",
    "        lowest_error_for_C = float(\"inf\")\n",
    "        best_params_for_C = None\n",
    "        for gamma in gamma_values:\n",
    "            for a in a_values:\n",
    "                # Initialize and train the SVM\n",
    "                \n",
    "                svm = SVMpkg.PrimalSVM(gamma=gamma, a=a, C=C, N=N)\n",
    "                svm.fit(X_train, y_train, epochs=epochs, schedule=schedule)\n",
    "\n",
    "                # Calculate training and test errors\n",
    "                train_error = svm.score(X_train, y_train)\n",
    "                test_error = svm.score(X_test, y_test)\n",
    "                weights = svm.get_weights()\n",
    "                bias = svm.get_bias()\n",
    "\n",
    "                #print(f\"Schedule: {schedule}, C={C:.6f}, gamma={gamma}, a={a}, \"\n",
    "                #f\"train_error: {train_error:.4f}, test_error: {test_error:.4f},\"\n",
    "                #f\"weights, {weights}, bias = {bias}\")\n",
    "\n",
    "                #output objective curve \n",
    "                #objective_curve = svm.get_objective_curve()\n",
    "                #plt.figure(figsize=(8, 5))\n",
    "                #plt.plot(range(1, len(objective_curve) + 1), objective_curve, marker='o')\n",
    "                #plt.title(\"Objective Function Curve (Hinge Loss)\")\n",
    "                #plt.xlabel(\"Epoch\")\n",
    "                #plt.ylabel(\"Hinge Loss\")\n",
    "                #plt.grid(True)\n",
    "                #plt.show()\n",
    "\n",
    "                # Update the best parameters for the current C\n",
    "                if test_error < lowest_error_for_C:\n",
    "                    lowest_error_for_C = test_error\n",
    "                    best_params_for_C = {\n",
    "                        \"C\": C,\n",
    "                        \"gamma\": gamma,\n",
    "                        \"a\": a,\n",
    "                        \"schedule\": schedule,\n",
    "                        \"train_error\": train_error,\n",
    "                        \"test_error\": test_error,\n",
    "                        \"weights\": weights,\n",
    "                        \"bias\": bias\n",
    "                    }\n",
    "        \n",
    "        # Store the best parameters for the current C and schedule\n",
    "        best_params_per_schedule[schedule][C] = best_params_for_C\n",
    "\n",
    "# Print the best parameters for each C, separated by schedule\n",
    "for schedule, params_per_C in best_params_per_schedule.items():\n",
    "    print(f\"\\nBest Parameters for {schedule}:\")\n",
    "    for C, params in params_per_C.items():\n",
    "        print(f\"C={C:.6f}, Schedule: {params['schedule']}, gamma={params['gamma']}, a={params['a']}, \"\n",
    "              f\"train_error: {params['train_error']:.4f}, test_error: {params['test_error']:.4f}, \"\n",
    "              f\"weights: {params['weights']}, bias: {params['bias']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\EID-Download\\02 Academic\\Python38\\lib\\site-packages\\scipy\\optimize\\_optimize.py:353: RuntimeWarning: Values in x were outside bounds during a minimize step, clipping to bounds\n",
      "  warnings.warn(\"Values in x were outside bounds during a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1145475372279496, Train error=0.11, Test error=0.12\n",
      "Weights:, [-0.94292598 -0.65149184 -0.73372197 -0.04102195], Bias:, 4.14119177534919\n",
      "C=0.572737686139748, Train error=0.15, Test error=0.14\n",
      "Weights:, [-1.56393784 -1.01405165 -1.18065044 -0.15651687], Bias:, 7.590350666124916\n",
      "C=0.8018327605956472, Train error=0.40, Test error=0.43\n",
      "Weights:, [-2.04254833 -1.28068891 -1.51351532 -0.24905307], Bias:, 12.975949611428163\n",
      "Weights: [-2.04254833 -1.28068891 -1.51351532 -0.24905307]\n",
      "Bias: 12.975949611428163\n"
     ]
    }
   ],
   "source": [
    "#DualSVM\n",
    "Cs = [100 / 873, 500 / 873, 700 / 873] #, 873\n",
    "\n",
    "# Train and evaluate the model for different values of C\n",
    "for C in Cs:\n",
    "    svm = SVMpkg.DualSVM(C)\n",
    "    svm.fit(X_train, y_train)\n",
    "    train_error = svm.score(X_train, y_train)\n",
    "    test_error = svm.score(X_test, y_test)\n",
    "    print(f\"C={C}, Train error={train_error:.2f}, Test error={test_error:.2f}\")\n",
    "    print(f\"Weights:, {svm.w}, Bias:, {svm.b}\")\n",
    "\n",
    "# Print the weights and bias for the best model\n",
    "print(\"Weights:\", svm.w)\n",
    "print(\"Bias:\", svm.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -82.72279493439663\n",
      "            Iterations: 15\n",
      "            Function evaluations: 13098\n",
      "            Gradient evaluations: 15\n",
      "C=0.1145, gamma=0.1, Train error=0.4461, Test error=0.4420, Number of Support Vectors: 853\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -74.16551934430456\n",
      "            Iterations: 23\n",
      "            Function evaluations: 20084\n",
      "            Gradient evaluations: 23\n",
      "C=0.1145, gamma=0.5, Train error=0.4071, Test error=0.4260, Number of Support Vectors: 745\n"
     ]
    }
   ],
   "source": [
    "#GaussianSVM\n",
    "Cs = [100 / 873, 500 / 873, 700 / 873] #, 873\n",
    "gammas = [0.1, 0.5, 1, 5, 100]\n",
    "\n",
    "lowest_error = float(\"inf\")\n",
    "best_params = None\n",
    "\n",
    "for C in Cs:\n",
    "    for gamma in gammas:\n",
    "        gsvm = SVMpkg.GaussianSVM(C, gamma)\n",
    "        gsvm.fit(X_train, y_train)\n",
    "        sv_indices = gsvm.get_support_vectors()\n",
    "        train_error = gsvm.score(X_train, y_train)\n",
    "        test_error = gsvm.score(X_test, y_test)\n",
    "        print(f\"C={C:.4f}, gamma={gamma}, Train error={train_error:.4f}, Test error={test_error:.4f}, Number of Support Vectors: {len(sv_indices)}\")\n",
    "\n",
    "        if test_error < lowest_error:\n",
    "            lowest_error = test_error\n",
    "            best_params = (C, gamma)\n",
    "\n",
    "print(f\"Best Parameters: C={best_params[0]:.4f}, gamma={best_params[1]}\")\n",
    "print(f\"Best Test Error: {lowest_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GaussianSVM\n",
    "C = 500 / 873 \n",
    "gammas = [0.01, 0.1, 0.5, 1, 5]\n",
    "\n",
    "# Track support vectors\n",
    "support_vectors = {}\n",
    "for gamma in gammas:\n",
    "    gsvm = SVMpkg.GaussianSVM(C=C, gamma=gamma)\n",
    "    gsvm.fit(X_train, y_train)\n",
    "    sv_indices = gsvm.get_support_vectors()\n",
    "    support_vectors[gamma] = sv_indices\n",
    "    print(f\"Gamma={gamma}, Number of Support Vectors: {len(sv_indices)}\")\n",
    "\n",
    "# Calculate overlaps between consecutive gammas\n",
    "for i in range(len(gammas) - 1):\n",
    "    gamma1, gamma2 = gammas[i], gammas[i + 1]\n",
    "    overlap = len(np.intersect1d(support_vectors[gamma1], support_vectors[gamma2]))\n",
    "    print(f\"Overlap between gamma={gamma1} and gamma={gamma2}: {overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel Perceptron\n",
    "gammas = [0.1, 0.5, 1, 5, 100]\n",
    "for gamma in gammas:\n",
    "    kp = SVMpkg.KernelPerceptron(gamma=gamma)\n",
    "    kp.fit(X_train, y_train)\n",
    "    train_error = kp.score(X_train, y_train)\n",
    "    test_error = kp.score(X_test, y_test)\n",
    "    print(f\"Gamma={gamma}, Train error ={train_error:.4f}, Test error ={test_error:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
