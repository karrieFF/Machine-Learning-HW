{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import math\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Question 2-1: ID3 tree"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#calculate entropy\n","def entropy (data, label):\n","\n","    unique_type = data[label].value_counts() #update the code to not calculate in a loop\n","    probabilities = unique_type / len(data)\n","    entropy = -sum(probabilities * probabilities.apply(math.log2))\n","    \n","    return entropy\n","\n","def ME_fun(data, label):\n","    unique_type = data[label].value_counts()\n","    min_category = unique_type.min()\n","    total_category = unique_type.sum()\n","    me_value = min_category/total_category\n","    return(me_value) #\n","\n","def Gini(data, label):\n","    unique_type = data[label].value_counts(normalize=True)\n","    sum_category = sum(unique_type ** 2)\n","    gini = 1 - sum_category\n","    \n","    return(gini)\n","\n","def information_gain_fun(data, type, y): \n","\n","    len_x = len(data.columns)-1\n","\n","    if type == 'en':\n","        total_entropy = entropy(data, y)\n","    elif type == \"me\":\n","        total_entropy = ME_fun(data, y)\n","    elif type == \"gini\":\n","        total_entropy = Gini(data, y)\n","    else:\n","        #print('Default is entropy')\n","        total_entropy = entropy(data, y)\n","\n","    output_table = pd.DataFrame(columns = ['factor','decision_value'])\n","\n","    for i in range(len_x):\n","        varx = data.columns[i]\n","        varx_categorpy = data[varx].unique()\n","        \n","        entropy_lst = []\n","        len_var = len(data[varx])\n","\n","        for i in sorted(varx_categorpy):\n","            varsub = data[data[varx] == i] #x = 1 data\n","            \n","            if type == 'en':\n","                varsub_entropy = entropy(varsub, y)\n","            elif type == \"me\":\n","                varsub_entropy = ME_fun(varsub, y)\n","            elif type == \"gini\":\n","                varsub_entropy = Gini(varsub, y)\n","            else:\n","                #print('Default is entropy')\n","                varsub_entropy = entropy(varsub, y)\n","\n","            proportion= len(varsub)/len_var\n","            entropy_var_category = proportion*varsub_entropy\n","            entropy_lst.append(entropy_var_category)\n","\n","        expected_entropy = sum(entropy_lst)\n","        information_gain = total_entropy - expected_entropy\n","        row = {'factor': varx,\"decision_value\":information_gain}\n","        output_table = pd.concat([output_table, pd.DataFrame([row])], ignore_index = True)\n","\n","\n","    # Find the index of the maximum value in the 'decision_value' column\n","    max_index = output_table['decision_value'].idxmax()\n","\n","    # Get the corresponding factor\n","    max_factor = output_table.loc[max_index, 'factor']\n","    return (max_factor)\n","\n","def ID3 (data, type, y, features, current_depth, max_depth):\n","    trees = {}\n","    \n","    #If all target labels are the same, return label\n","    if data[y].nunique() == 1:\n","        output_y = data[y].unique()[0]\n","        return output_y\n","\n","    # If no more features are available, return the most common label\n","    elif len(features) == 0 or (current_depth >= max_depth) :\n","        return data[y].mode()[0]\n","        \n","    else:\n","        best_feature1 = information_gain_fun(data, type, y)\n","        #Innitial tree with best features:\n","        trees[best_feature1] = {}\n","\n","        for i in data[best_feature1].unique():\n","\n","            split_tree_data = data[data[best_feature1] == i]\n","            if split_tree_data.empty:\n","                trees[best_feature1][i] = data[y].mode()[0]\n","\n","            else:\n","                new_features = [f for f in features if f != best_feature1]\n","                update_data = split_tree_data.loc[:, split_tree_data.columns != best_feature1]\n","                subtree = ID3(update_data, type, y, new_features, current_depth+1, max_depth) #call ID3 again\n","                trees[best_feature1][i] = subtree\n","        return trees\n","\n","def predict (trees, predictors):\n","\n","    if not isinstance(trees, dict):\n","        return trees\n","\n","    parent_node = next(iter(trees)) #parent node\n","    subtree = trees[parent_node] #subtree of parent_node\n","    feature_value = predictors[parent_node]  #the value of the parent in the first observation\n","\n","    if feature_value in subtree:\n","        return predict(subtree[feature_value], predictors)\n","    \n","    else: \n","        return None\n","    \n","def evaluation(trees, verify_data, features, y): #test\n","    \n","    inaccurate_case = 0\n","    num_rows = len(verify_data)\n","\n","    for i, row in verify_data.iterrows():\n","        true_y = row[y] #true y\n","        predictors = row[features].to_dict()\n","        predict_value = predict(trees, predictors) #predicted y\n","        \n","        if predict_value != true_y:\n","            inaccurate_case += 1 #total inaccurate prediction case\n","\n","    predicted_error = inaccurate_case/num_rows #prediction error\n","    \n","    return(predicted_error)"]},{"cell_type":"markdown","metadata":{},"source":["Question 2-2: car data"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["#load data\n","train_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\car\\\\train.csv\", header = None, names = ['buying','maint','doors','persons','lug_boot','safety','label'])\n","test_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\car\\\\test.csv\", header = None, names = ['buying','maint','doors','persons','lug_boot','safety','label'])\n","\n","#Main function\n","features = ['buying','maint','doors','persons','lug_boot','safety']\n","max_depth_lst = [i for i in range(1,7)]\n","type3 = ['en', 'me', 'gini'] #three types of approach to calculate the information gain\n","y = 'label'\n","current_depth = 0\n","comparison_lst = []\n","\n","for type in type3:\n","    for max_depth in max_depth_lst:\n","        trees = ID3 (train_data, type, y, features, current_depth, max_depth)\n","        predicted_error_train = evaluation(trees, train_data, features, y)\n","        predicted_error_test = evaluation(trees, test_data, features, y)\n","        \n","        comparison_lst.append({\n","            \"Criterion\": type,\n","            \"Max Depth\": max_depth,\n","            \"training_error\":predicted_error_train,\n","            \"testing_error\":predicted_error_test\n","        })\n","\n","car_compare_table = pd.DataFrame(comparison_lst)\n","car_compare_table\n","car_compare_table.to_csv('car_comparison_table.csv')"]},{"cell_type":"markdown","metadata":{},"source":["Question 3 Bank data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#load data\n","train_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\bank\\\\train.csv\",header = None, \n","names = ['age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','y'])\n","\n","test_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\bank\\\\test.csv\", header = None, \n","names = ['age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','y'])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#regard unknown as a particular attribute\n","def data_preprocessing_attribute(data, features, continuous):\n","    for var in features:\n","        if var in continuous:\n","            media = data[var].median() #replace with median\n","            data[var] = data[var].apply(lambda x:\"no\" if x < media else 'yes')\n","\n","    return data\n","\n","#regard unknown as a missing value and replace it with the majority of other values of the same attributes\n","def data_preprocessing_missing(data, features, continuous):\n","    for var1 in features:\n","        if var1 in continuous:\n","            media = data[var1].median() #replace with median\n","            data[var1] = data[var1].apply(lambda x:\"no\" if x < media else 'yes')\n","        else:\n","            data[var1].replace('unknown', np.nan, inplace = True)\n","            mode_factor = data[var1].mode()[0]\n","            data[var1].replace(np.nan, mode_factor, inplace = True)\n","        \n","    return data"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["#Main function\n","features = ['age', 'job', 'marital','education', 'default', 'balance', 'housing','loan', 'contact', 'day','month', \n","            'duration','campaign','pdays','previous', 'poutcome']\n","\n","continuous = ['age', 'balance', 'day','duration','campaign','pdays','previous']\n","\n","#load data\n","train_data_att = data_preprocessing_attribute(train_data.copy(), features, continuous)\n","test_data_att = data_preprocessing_attribute(test_data.copy(), features, continuous)\n","\n","max_depth_lst = [i for i in range(1,17)]  #range from 1-16\n","type3 = ['en', 'me', 'gini']\n","y = 'y'\n","current_depth = 0\n","comparison_lst = []\n","\n","for type in type3:\n","    for max_depth in max_depth_lst:\n","        trees = ID3 (train_data_att, type, y, features, current_depth, max_depth)\n","        predicted_error_train = evaluation(trees, train_data_att, features, y)\n","        predicted_error_test = evaluation(trees, test_data_att, features, y)\n","        \n","        comparison_lst.append({\n","            \"Criterion\": type,\n","            \"Max Depth\": max_depth,\n","            \"training_error\":predicted_error_train,\n","            \"testing_error\":predicted_error_test\n","        })\n","    \n","        #print(type, max_depth, predicted_error_train, predicted_error_test)\n","bank_att_compare_table = pd.DataFrame(comparison_lst)\n","bank_att_compare_table.to_csv('bank_att_comparison_table_v3.csv')"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["#load data\n","train_data_miss = data_preprocessing_missing(train_data.copy(), features, continuous)\n","test_data_miss = data_preprocessing_missing(test_data.copy(), features, continuous)\n","\n","max_depth_lst = [i for i in range(1,17)] #range from 1-16\n","type3 = ['en', 'me', 'gini']\n","y = 'y'\n","current_depth = 0\n","comparison_lst = []\n","\n","for type in type3:\n","    for max_depth in max_depth_lst:\n","        trees = ID3 (train_data_miss, type, y, features, current_depth, max_depth)\n","        predicted_error_train = evaluation(trees, train_data_miss, features, y)\n","        predicted_error_test = evaluation(trees, test_data_miss, features, y)\n","        \n","        comparison_lst.append({\n","            \"Criterion\": type,\n","            \"Max Depth\": max_depth,\n","            \"training_error\":predicted_error_train,\n","            \"testing_error\":predicted_error_test\n","        })\n","    \n","        #print(type, max_depth, predicted_error_train, predicted_error_test)\n","bank_miss_compare_table = pd.DataFrame(comparison_lst)\n","bank_miss_compare_table\n","bank_miss_compare_table.to_csv('bank_miss_comparison_table_v3.csv')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"}},"nbformat":4,"nbformat_minor":2}
