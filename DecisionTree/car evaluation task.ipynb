{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import math\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#load data\n","train_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\car\\\\train.csv\", header = None, names = ['buying','maint','doors','persons','lug_boot','safety','label'])\n","test_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\car\\\\test.csv\", header = None, names = ['buying','maint','doors','persons','lug_boot','safety','label'])"]},{"cell_type":"markdown","metadata":{},"source":["Processing data"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["buying      0\n","maint       0\n","doors       0\n","persons     0\n","lug_boot    0\n","safety      0\n","label       0\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#detect missing value\n","train_data.isna().sum() #"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["#replace str to value\n","train_data.replace({\"low\":1, \"med\":2, 'high':3, 'vhigh':4,'5more':5, 'more':5, \"small\":1,\"big\":3, 'unacc':1, 'acc':2, 'good':3, 'vgood':4}, inplace = True)\n","train_data = train_data.astype('int') #transfer data to int format\n","test_data.replace({\"low\":1, \"med\":2, 'high':3, 'vhigh':4,'5more':5, 'more':5, \"small\":1,\"big\":3, 'unacc':1, 'acc':2, 'good':3, 'vgood':4}, inplace = True)\n","test_data = test_data.astype('int') #transfer data to int format"]},{"cell_type":"markdown","metadata":{},"source":["| label values\n","\n","unacc(1), acc(2), good(3), vgood(4)\n","\n","| attributes\n","\n","buying:   vhigh(4), high(3), med(2), low(1).\n","\n","maint:    vhigh(4), high(3), med(2), low(1).\n","\n","doors:    2, 3, 4, 5more(5).\n","\n","persons:  2, 4, more(5).\n","\n","lug_boot: small(1), med(2), big(3).\n","\n","safety:   low(1), med(2), high(3)."]},{"cell_type":"markdown","metadata":{},"source":["Function for calculating information gain"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#calculate entropy\n","def entropy (data, label):\n","\n","    entropy = 0\n","\n","    unique_type = sorted(data[label].unique())\n","    sum_type = []\n","    for i in unique_type:\n","        #lable is the outcome\n","        subvalue = len(data[data[label] == i])/len(data)\n","        sublog = subvalue*math.log2(subvalue)\n","        sum_type.append(sublog)\n","\n","    if 0 not in sum_type: # decide if the tree equal to zero\n","        entropy = - sum(sum_type)\n","\n","    return entropy"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def ME_fun(data, label):\n","    \n","    unique_type = sorted(data[label].unique())\n","    sum_type = []\n","    for i in unique_type:\n","        #lable is the outcome\n","        subvalue = len(data[data[label] == i])\n","        sum_type.append(subvalue)\n","\n","    min_category = min(sum_type)\n","    total_category = sum(sum_type)\n","    me_value = min_category/total_category\n","    return(me_value) #"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def Gini(data, label):\n","    \n","    unique_type = sorted(data[label].unique())\n","    sum_type = []\n","\n","    for i in unique_type:\n","        #lable is the outcome\n","        subvalue = len(data[data[label] == i])/len(data)\n","        subvalue2 = math.pow(subvalue, 2)\n","        sum_type.append(subvalue)\n","\n","    sum_category = sum(sum_type)\n","    gini = 1 - sum_category\n","\n","    return(gini)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def information_gain_fun(data, type, y): \n","\n","    copy_data_frame = data\n","    len_x = len(copy_data_frame.columns)-1\n","\n","    if type == 'en':\n","        total_entropy = entropy(copy_data_frame, y)\n","    elif type == \"me\":\n","        total_entropy = ME_fun(copy_data_frame, y)\n","    elif type == \"gini\":\n","        total_entropy = Gini(copy_data_frame, y)\n","    else:\n","        #print('Default is entropy')\n","        total_entropy = entropy(copy_data_frame, y)\n","\n","    output_table = pd.DataFrame(columns = ['factor','decision_value'])\n","\n","    for i in range(len_x):\n","        varx = copy_data_frame.columns[i]\n","        varx_categorpy = copy_data_frame[varx].unique()\n","        \n","        entropy_lst = []\n","        len_var = len(copy_data_frame[varx])\n","\n","        for i in sorted(varx_categorpy):\n","            varsub = copy_data_frame[copy_data_frame[varx] == i] #x = 1 data\n","            if type == 'en':\n","                varsub_entropy = entropy(varsub, y)\n","            elif type == \"me\":\n","                varsub_entropy = ME_fun(varsub, y)\n","            elif type == \"gini\":\n","                varsub_entropy = Gini(varsub, y)\n","            else:\n","                #print('Default is entropy')\n","                varsub_entropy = entropy(varsub, y)\n","\n","            proportion= len(varsub)/len_var\n","            entropy_var_category = proportion*varsub_entropy\n","            entropy_lst.append(entropy_var_category)\n","\n","        expected_entropy = sum(entropy_lst)\n","        information_gain = total_entropy - expected_entropy\n","        row = {'factor': varx,\"decision_value\":information_gain}\n","        output_table = pd.concat([output_table, pd.DataFrame([row])], ignore_index = True)\n","\n","\n","    # Find the index of the maximum value in the 'decision_value' column\n","    max_index = output_table['decision_value'].idxmax()\n","\n","    # Get the corresponding factor\n","    max_factor = output_table.loc[max_index, 'factor']\n","    return (max_factor)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def ID3 (data, type, y, features, current_depth, max_depth):\n","    trees = {}\n","    used_data = data\n","    \n","    #If all target labels are the same, return label\n","    if used_data[y].nunique() == 1:\n","        output_y = used_data[y].unique()[0]\n","        output_y2 = f\"y = {output_y}\"\n","        return output_y2\n","\n","    # If no more features are available, return the most common label\n","    elif len(features) == 0 or (current_depth > max_depth) :\n","        return used_data[y].mode()[0]\n","        \n","    else:\n","        best_feature1 = information_gain_fun(used_data, type, y)\n","        best_features_category = sorted(used_data[best_feature1].unique())\n","        \n","        #Innitial tree with best features:\n","        trees[best_feature1] = {}\n","\n","        for i in best_features_category:\n","            split_tree_data = used_data[used_data[best_feature1] == i]\n","            if split_tree_data.empty:\n","                trees[best_features1][i] = used_data[y].mode()[0]\n","\n","            else:\n","                new_features = [f for f in features if f != best_feature1]\n","                update_data = split_tree_data.loc[:, split_tree_data.columns != best_feature1]\n","                subtree = ID3(update_data, type, y, new_features, current_depth+1, max_depth) #call ID3 again\n","                trees[best_feature1][i] = subtree\n","        return trees"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def predict (tree, predictors):\n","\n","    if not isinstance(tree, dict):\n","        return tree\n","\n","    parent_node = next(iter(trees)) #parent node\n","    subtree = trees[parent_node] #subtree of parent_node\n","    feature_value = predictors[parent_node]  #the value of the parent in the first observation\n","\n","    if feature_value in subtree:\n","        return predict(subtree[feature_value], predictors)\n","    \n","    else: \n","        return None\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["def evaluation(verify_data, features, y): #test\n","    \n","    inaccurate_case = 0\n","    num_rows = len(verify_data)\n","\n","    for i in range(num_rows):\n","        row = verify_data.iloc[0]\n","        true_y = row[y] #true y\n","        predictors = row[features]\n","        predict_value = predict(trees, predictors) #predicted y\n","        \n","        if predict_value != true_value:\n","            inaccurate_case += 1 #total inaccurate prediction case\n","\n","    predicted_error = inaccurate_case/num_rows #prediction error\n","    \n","    return(predicted_error)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#Main function\n","features = ['buying','maint','doors','persons','lug_boot','safety']\n","data = train_data\n","y = 'label'\n","type = 'en'   # 'en', 'me', 'gini'\n","max_depth = 2  # decide the largest number of depth\n","verify_data = train_data #test_data\n","\n","trees = ID3 (data, type, y, features, current_depth=0, max_depth)\n","predicted_error = evaluation(verify_data, features, y)"]},{"cell_type":"markdown","metadata":{},"source":["Question 3"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["#load data\n","train_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\bank\\\\train.csv\",header = None, \n","names = ['age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','y'])\n","\n","test_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\Machine-Learning-HW\\\\DecisionTree\\\\bank\\\\test.csv\", header = None, \n","names = ['age','job','marital','education','default','balance','housing','loan','contact','day','month','duration','campaign','pdays','previous','poutcome','y'])"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["#continuous variable: age, balance, day, duration, empaign, pdays, previous \n","#trainsfer continuous variables to category\n","def data_preprocessing(data, continuous, category):\n","    for var in continuous:\n","        mode = data[var].mode()[0]\n","        data[var] = data[var].map(lambda x:0 if x < mode else 1)\n","\n","    for var2 in category:\n","        data[var2] = pd.Categorical(data[var2],\n","                                        categories = data[var2].unique(),\n","                                        ordered=True)\n","        data[var2] = data[var2].cat.codes\n","\n","    return data"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["continuous = ['age', 'balance', 'day','duration','campaign','pdays','previous']\n","category = ['job','marital','education','default','housing','loan','contact','month','poutcome','y']\n","update_train = data_preprocessing(train_data, continuous,category)\n","update_test = data_preprocessing(test_data, continuous,category)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"}},"nbformat":4,"nbformat_minor":2}
